{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "airflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKfoP1dL_IAy",
        "outputId": "18725a5b-9f8e-4bec-8e0c-27d3316e1a46"
      },
      "source": [
        "! pip install apache-airflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-airflow\n",
            "  Downloading apache_airflow-2.1.4-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (3.7.4.3)\n",
            "Collecting colorlog<6.0,>=4.0.2\n",
            "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting unicodecsv>=0.14.1\n",
            "  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting graphviz>=0.12\n",
            "  Downloading graphviz-0.17-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.0)\n",
            "Collecting markupsafe<2.0,>=1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Requirement already satisfied: argcomplete~=1.10 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.12.3)\n",
            "Requirement already satisfied: tabulate<0.9,>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (0.8.9)\n",
            "Collecting pyjwt<2\n",
            "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting apache-airflow-providers-imap\n",
            "  Downloading apache_airflow_providers_imap-2.0.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pygments<3.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (2.6.1)\n",
            "Collecting apache-airflow-providers-sqlite\n",
            "  Downloading apache_airflow_providers_sqlite-2.0.1-py3-none-any.whl (15 kB)\n",
            "Collecting openapi-spec-validator>=0.2.4\n",
            "  Downloading openapi_spec_validator-0.3.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.18 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.4.25)\n",
            "Collecting apache-airflow-providers-ftp\n",
            "  Downloading apache_airflow_providers_ftp-2.0.1-py3-none-any.whl (15 kB)\n",
            "Collecting alembic<2.0,>=1.2\n",
            "  Downloading alembic-1.7.3-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting docutils<0.17\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2<4,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (2.11.3)\n",
            "Collecting apache-airflow-providers-http\n",
            "  Downloading apache_airflow_providers_http-2.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting pendulum~=2.0\n",
            "  Downloading pendulum-2.1.2-cp37-cp37m-manylinux1_x86_64.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 56.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.0)\n",
            "Collecting tenacity~=6.2.0\n",
            "  Downloading tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0,>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.5)\n",
            "Requirement already satisfied: psutil<6.0.0,>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (5.4.8)\n",
            "Collecting swagger-ui-bundle>=0.0.2\n",
            "  Downloading swagger_ui_bundle-0.0.9-py3-none-any.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 35.6 MB/s \n",
            "\u001b[?25hCollecting flask-caching<2.0.0,>=1.5.0\n",
            "  Downloading Flask_Caching-1.10.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (4.8.1)\n",
            "Collecting inflection>=0.3.1\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.19.5)\n",
            "Collecting lockfile>=0.12.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: flask<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.4)\n",
            "Requirement already satisfied: dill<0.4,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (0.3.4)\n",
            "Collecting croniter<1.1,>=0.3.17\n",
            "  Downloading croniter-1.0.15-py2.py3-none-any.whl (16 kB)\n",
            "Collecting jsonschema~=3.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting python-daemon>=2.2.4\n",
            "  Downloading python_daemon-2.3.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting setproctitle<2,>=1.1.8\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Collecting sqlalchemy-jsonfield~=1.0\n",
            "  Downloading SQLAlchemy_JSONField-1.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting attrs<21.0,>=20.0\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting python-slugify<5.0,>=3.0.0\n",
            "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
            "Requirement already satisfied: cached-property~=1.5 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.5.2)\n",
            "Collecting cattrs<1.7.0,~=1.1\n",
            "  Downloading cattrs-1.5.0-py3-none-any.whl (19 kB)\n",
            "Collecting python-nvd3~=0.15.0\n",
            "  Downloading python-nvd3-0.15.0.tar.gz (31 kB)\n",
            "Collecting marshmallow-oneofschema>=2.0.1\n",
            "  Downloading marshmallow_oneofschema-3.0.1-py2.py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1,~=1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.0.1)\n",
            "Collecting clickclick>=1.2\n",
            "  Downloading clickclick-20.10.2-py2.py3-none-any.whl (7.4 kB)\n",
            "Collecting iso8601>=0.1.12\n",
            "  Downloading iso8601-0.1.16-py2.py3-none-any.whl (10 kB)\n",
            "Collecting importlib-resources~=1.4\n",
            "  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: markdown<4.0,>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (3.3.4)\n",
            "Collecting python3-openid~=3.2\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (2.8.2)\n",
            "Collecting cryptography>=0.9.3\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 50.0 MB/s \n",
            "\u001b[?25hCollecting rich>=9.2.0\n",
            "  Downloading rich-10.11.0-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 56.6 MB/s \n",
            "\u001b[?25hCollecting flask-wtf<0.15,>=0.14.3\n",
            "  Downloading Flask_WTF-0.14.3-py2.py3-none-any.whl (13 kB)\n",
            "Collecting lazy-object-proxy\n",
            "  Downloading lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting gunicorn>=19.5.0\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting flask-login<0.5,>=0.3\n",
            "  Downloading Flask-Login-0.4.1.tar.gz (14 kB)\n",
            "Collecting flask-appbuilder<4.0.0,>=3.3.2\n",
            "  Downloading Flask_AppBuilder-3.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 32.1 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from clickclick>=1.2->apache-airflow) (7.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=0.9.3->apache-airflow) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=0.9.3->apache-airflow) (2.20)\n",
            "Collecting Flask-SQLAlchemy<3,>=2.4\n",
            "  Downloading Flask_SQLAlchemy-2.5.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting marshmallow-enum<2,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting marshmallow<4,>=3\n",
            "  Downloading marshmallow-3.13.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting email-validator<2,>=1.0.5\n",
            "  Downloading email_validator-1.1.3-py2.py3-none-any.whl (18 kB)\n",
            "Collecting Flask-Babel<2,>=1\n",
            "  Downloading Flask_Babel-1.0.0-py3-none-any.whl (9.5 kB)\n",
            "Collecting sqlalchemy-utils<1,>=0.32.21\n",
            "  Downloading SQLAlchemy_Utils-0.37.8-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting sqlalchemy>=1.3.18\n",
            "  Downloading SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting marshmallow-sqlalchemy<0.24.0,>=0.22.0\n",
            "  Downloading marshmallow_sqlalchemy-0.23.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting Flask-OpenID<2,>=1.2.5\n",
            "  Downloading Flask_OpenID-1.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting apispec[yaml]<4,>=3.3\n",
            "  Downloading apispec-3.3.2-py2.py3-none-any.whl (27 kB)\n",
            "Collecting colorama<1,>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting prison<1.0.0,>=0.2.1\n",
            "  Downloading prison-0.2.1-py2.py3-none-any.whl (5.8 kB)\n",
            "Collecting Flask-JWT-Extended<4,>=3.18\n",
            "  Downloading Flask-JWT-Extended-3.25.1.tar.gz (32 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from email-validator<2,>=1.0.5->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow) (2.10)\n",
            "Collecting dnspython>=1.15.0\n",
            "  Downloading dnspython-2.1.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 617 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel<2,>=1->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow) (2018.9)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel<2,>=1->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow) (2.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Flask-JWT-Extended<4,>=3.18->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow) (1.15.0)\n",
            "Collecting WTForms\n",
            "  Downloading WTForms-2.3.3-py2.py3-none-any.whl (169 kB)\n",
            "\u001b[K     |████████████████████████████████| 169 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn>=19.5.0->apache-airflow) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7->apache-airflow) (3.5.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema~=3.0->apache-airflow) (0.18.0)\n",
            "Collecting openapi-schema-validator\n",
            "  Downloading openapi_schema_validator-0.1.5-py3-none-any.whl (7.9 kB)\n",
            "Collecting pytzdata>=2020.1\n",
            "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
            "\u001b[K     |████████████████████████████████| 489 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify<5.0,>=3.0.0->apache-airflow) (1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from python3-openid~=3.2->apache-airflow) (0.7.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 817 kB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-airflow-providers-http->apache-airflow) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-airflow-providers-http->apache-airflow) (2.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-airflow-providers-http->apache-airflow) (1.24.3)\n",
            "Collecting httpcore<0.14.0,>=0.13.3\n",
            "  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting anyio==3.*\n",
            "  Downloading anyio-3.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Flask-JWT-Extended, flask-login, python-nvd3, python-slugify, unicodecsv, blinker\n",
            "  Building wheel for Flask-JWT-Extended (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Flask-JWT-Extended: filename=Flask_JWT_Extended-3.25.1-py2.py3-none-any.whl size=21614 sha256=ad34ac78e86721139545e8a059a449bacbcbf3393181cc9c0ce310e75eae4b77\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/ae/4e/9a2aaa24195ac393559452efb4e82c4dcc3192602886f7a81e\n",
            "  Building wheel for flask-login (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-login: filename=Flask_Login-0.4.1-py2.py3-none-any.whl size=15949 sha256=a7d4eec8169be403e04492a538f13510092b67871514a828e177918f0431f289\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/b8/33/1da5a5d39e093a68d81848aa44fd70e3cd0193e6f2d5641052\n",
            "  Building wheel for python-nvd3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-nvd3: filename=python_nvd3-0.15.0-py3-none-any.whl size=38164 sha256=328a7bbe5dfcee52134a0d9977a184faa5603762cb79f8f68b37bb8b9c17a9b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/0e/a4/5290cd4d309d756617f4d8eedd60813653d606e21ccaf7f286\n",
            "  Building wheel for python-slugify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-slugify: filename=python_slugify-4.0.1-py2.py3-none-any.whl size=6781 sha256=db389d3060615f884307201233000f2628c5361708a793afdd812526184a0473\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/1b/6f/5c1cfab22eacbe0095fc619786da6571b55253653c71324b5c\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10765 sha256=ce6815a2ce3cdf67311343eb5e6732ae6a3abd925c11cd3c031e449e26410d61\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=d77c2405e5f7874b7217a413f0ec1cf9f2ecb9d57a188b246a8c472ffbe895a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built Flask-JWT-Extended flask-login python-nvd3 python-slugify unicodecsv blinker\n",
            "Installing collected packages: markupsafe, sniffio, attrs, WTForms, sqlalchemy, rfc3986, pyyaml, python3-openid, pyjwt, marshmallow, jsonschema, isodate, h11, dnspython, apispec, anyio, sqlalchemy-utils, requests, pytzdata, python-slugify, prison, openapi-schema-validator, marshmallow-sqlalchemy, marshmallow-enum, Mako, lockfile, importlib-resources, httpcore, flask-wtf, Flask-SQLAlchemy, Flask-OpenID, flask-login, Flask-JWT-Extended, Flask-Babel, email-validator, docutils, commonmark, colorama, unicodecsv, tenacity, swagger-ui-bundle, sqlalchemy-jsonfield, setproctitle, rich, python-nvd3, python-daemon, pendulum, openapi-spec-validator, marshmallow-oneofschema, lazy-object-proxy, iso8601, inflection, httpx, gunicorn, graphviz, flask-caching, flask-appbuilder, cryptography, croniter, colorlog, clickclick, cattrs, blinker, apache-airflow-providers-sqlite, apache-airflow-providers-imap, apache-airflow-providers-http, apache-airflow-providers-ftp, alembic, apache-airflow\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.25\n",
            "    Uninstalling SQLAlchemy-1.4.25:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.25\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: python-slugify\n",
            "    Found existing installation: python-slugify 5.0.2\n",
            "    Uninstalling python-slugify-5.0.2:\n",
            "      Successfully uninstalled python-slugify-5.0.2\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.2.2\n",
            "    Uninstalling importlib-resources-5.2.2:\n",
            "      Successfully uninstalled importlib-resources-5.2.2\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-1.0.0 Flask-JWT-Extended-3.25.1 Flask-OpenID-1.3.0 Flask-SQLAlchemy-2.5.1 Mako-1.1.5 WTForms-2.3.3 alembic-1.7.3 anyio-3.3.2 apache-airflow-2.1.4 apache-airflow-providers-ftp-2.0.1 apache-airflow-providers-http-2.0.1 apache-airflow-providers-imap-2.0.1 apache-airflow-providers-sqlite-2.0.1 apispec-3.3.2 attrs-20.3.0 blinker-1.4 cattrs-1.5.0 clickclick-20.10.2 colorama-0.4.4 colorlog-5.0.1 commonmark-0.9.1 croniter-1.0.15 cryptography-3.4.8 dnspython-2.1.0 docutils-0.16 email-validator-1.1.3 flask-appbuilder-3.3.3 flask-caching-1.10.1 flask-login-0.4.1 flask-wtf-0.14.3 graphviz-0.17 gunicorn-20.1.0 h11-0.12.0 httpcore-0.13.7 httpx-0.19.0 importlib-resources-1.5.0 inflection-0.5.1 iso8601-0.1.16 isodate-0.6.0 jsonschema-3.2.0 lazy-object-proxy-1.6.0 lockfile-0.12.2 markupsafe-1.1.1 marshmallow-3.13.0 marshmallow-enum-1.5.1 marshmallow-oneofschema-3.0.1 marshmallow-sqlalchemy-0.23.1 openapi-schema-validator-0.1.5 openapi-spec-validator-0.3.1 pendulum-2.1.2 prison-0.2.1 pyjwt-1.7.1 python-daemon-2.3.0 python-nvd3-0.15.0 python-slugify-4.0.1 python3-openid-3.2.0 pytzdata-2020.1 pyyaml-5.4.1 requests-2.26.0 rfc3986-1.5.0 rich-10.11.0 setproctitle-1.2.2 sniffio-1.2.0 sqlalchemy-1.3.24 sqlalchemy-jsonfield-1.0.0 sqlalchemy-utils-0.37.8 swagger-ui-bundle-0.0.9 tenacity-6.2.0 unicodecsv-0.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7alKSE4UATwG",
        "outputId": "2bc0bba8-b874-4932-bc01-b231c205f430"
      },
      "source": [
        "!airflow initdb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: airflow [-h] GROUP_OR_COMMAND ...\n",
            "\n",
            "positional arguments:\n",
            "  GROUP_OR_COMMAND\n",
            "\n",
            "    Groups:\n",
            "      celery         Celery components\n",
            "      config         View configuration\n",
            "      connections    Manage connections\n",
            "      dags           Manage DAGs\n",
            "      db             Database operations\n",
            "      jobs           Manage jobs\n",
            "      kubernetes     Tools to help run the KubernetesExecutor\n",
            "      pools          Manage pools\n",
            "      providers      Display providers\n",
            "      roles          Manage roles\n",
            "      tasks          Manage tasks\n",
            "      users          Manage users\n",
            "      variables      Manage variables\n",
            "\n",
            "    Commands:\n",
            "      cheat-sheet    Display cheat sheet\n",
            "      info           Show information about current Airflow and environment\n",
            "      kerberos       Start a kerberos ticket renewer\n",
            "      plugins        Dump information about loaded plugins\n",
            "      rotate-fernet-key\n",
            "                     Rotate encrypted connection credentials and variables\n",
            "      scheduler      Start a scheduler instance\n",
            "      sync-perm      Update permissions for existing roles and optionally DAGs\n",
            "      version        Show the version\n",
            "      webserver      Start a Airflow webserver instance\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help         show this help message and exit\n",
            "\n",
            "airflow command error: argument GROUP_OR_COMMAND: `airflow initdb` command, has been removed, please use `airflow db init`, see help above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ1kNTbMAWwy",
        "outputId": "76328fb2-0828-409f-c1fe-e20970f2f6c1"
      },
      "source": [
        "!airflow webserver  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/psycopg2/\u001b[0m\u001b[1;33m__init__.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m144\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: The psycopg2 wheel package will be renamed from release \u001b[0m\u001b[1;33m2.8\u001b[0m\u001b[33m; in order to keep installing from binary please use \u001b[0m\u001b[33m\"pip install psycopg2-binary\"\u001b[0m\u001b[33m instead. For details see: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[4;33mhttp:\u001b[0m\u001b[4;33m//initd.org/psycopg/docs/install.html#binary-install-from-pypi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[33m.\u001b[0m\n",
            "[\u001b[34m2021-09-28 16:55:41,809\u001b[0m] {\u001b[34mcli_action_loggers.py:\u001b[0m105} \u001b[33mWARNING\u001b[0m - \u001b[33mFailed to log action with \u001b[01m(sqlite3.OperationalError) no such table: log\n",
            "[SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (?, ?, ?, ?, ?, ?, ?)]\n",
            "[parameters: ('2021-09-28 16:55:41.802564', None, None, 'cli_webserver', None, 'root', '{\"host_name\": \"61903c34964f\", \"full_command\": \"[\\'/usr/local/bin/airflow\\', \\'webserver\\']\"}')]\n",
            "(Background on this error at: http://sqlalche.me/e/13/e3q8)\u001b[22m\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
            "[\u001b[34m2021-09-28 16:55:41,817\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m496} INFO\u001b[0m - Filling up the DagBag from \u001b[01m/dev/null\u001b[22m\u001b[0m\n",
            "[\u001b[34m2021-09-28 16:55:42,019\u001b[0m] {\u001b[34mmanager.py:\u001b[0m788} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "Running the Gunicorn Server with:\n",
            "Workers: 4 sync\n",
            "Host: 0.0.0.0:8080\n",
            "Timeout: 120\n",
            "Logfiles: - -\n",
            "Access Logformat: \n",
            "=================================================================            \n",
            "[2021-09-28 16:55:49 +0000] [182] [INFO] Starting gunicorn 20.1.0\n",
            "[2021-09-28 16:55:49 +0000] [182] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-09-28 16:55:49 +0000] [182] [ERROR] Retrying in 1 second.\n",
            "[2021-09-28 16:55:50 +0000] [182] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-09-28 16:55:50 +0000] [182] [ERROR] Retrying in 1 second.\n",
            "[2021-09-28 16:55:51 +0000] [182] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-09-28 16:55:51 +0000] [182] [ERROR] Retrying in 1 second.\n",
            "[2021-09-28 16:55:52 +0000] [182] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-09-28 16:55:52 +0000] [182] [ERROR] Retrying in 1 second.\n",
            "[2021-09-28 16:55:53 +0000] [182] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-09-28 16:55:53 +0000] [182] [ERROR] Retrying in 1 second.\n",
            "[2021-09-28 16:55:54 +0000] [182] [ERROR] Can't connect to ('0.0.0.0', 8080)\n",
            "[\u001b[34m2021-09-28 16:57:48,752\u001b[0m] {\u001b[34mwebserver_command.py:\u001b[0m217} \u001b[31mERROR\u001b[0m - \u001b[31mNo response from gunicorn master within 120 seconds\u001b[0m\n",
            "[\u001b[34m2021-09-28 16:57:48,753\u001b[0m] {\u001b[34mwebserver_command.py:\u001b[0m218} \u001b[31mERROR\u001b[0m - \u001b[31mShutting down webserver\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xApLYvw5DCvo",
        "outputId": "b39dec9c-506d-49a8-db12-54e590d79d6d"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-28 16:57:49--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.237.133.81, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  41.6MB/s    in 0.3s    \n",
            "\n",
            "2021-09-28 16:57:49 (41.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kuja6fLDFb9",
        "outputId": "d6a135e1-743f-488c-e9d7-fe9268e61a0f"
      },
      "source": [
        "\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_s02vJACtg9",
        "outputId": "3d7d36ce-8678-464e-ea4c-34a6f32dbaec"
      },
      "source": [
        "!airflow initdb\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: airflow [-h] GROUP_OR_COMMAND ...\n",
            "\n",
            "positional arguments:\n",
            "  GROUP_OR_COMMAND\n",
            "\n",
            "    Groups:\n",
            "      celery         Celery components\n",
            "      config         View configuration\n",
            "      connections    Manage connections\n",
            "      dags           Manage DAGs\n",
            "      db             Database operations\n",
            "      jobs           Manage jobs\n",
            "      kubernetes     Tools to help run the KubernetesExecutor\n",
            "      pools          Manage pools\n",
            "      providers      Display providers\n",
            "      roles          Manage roles\n",
            "      tasks          Manage tasks\n",
            "      users          Manage users\n",
            "      variables      Manage variables\n",
            "\n",
            "    Commands:\n",
            "      cheat-sheet    Display cheat sheet\n",
            "      info           Show information about current Airflow and environment\n",
            "      kerberos       Start a kerberos ticket renewer\n",
            "      plugins        Dump information about loaded plugins\n",
            "      rotate-fernet-key\n",
            "                     Rotate encrypted connection credentials and variables\n",
            "      scheduler      Start a scheduler instance\n",
            "      sync-perm      Update permissions for existing roles and optionally DAGs\n",
            "      version        Show the version\n",
            "      webserver      Start a Airflow webserver instance\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help         show this help message and exit\n",
            "\n",
            "airflow command error: argument GROUP_OR_COMMAND: `airflow initdb` command, has been removed, please use `airflow db init`, see help above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "YheIxCvbA2Ef",
        "outputId": "625e8f97-21cc-4b89-df93-74ab2eda50a3"
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.operators.bash_operator import BashOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "\n",
        "def greet():\n",
        "    print('Writing in file')\n",
        "    with open('path/to/file/greet.txt', 'a+', encoding='utf8') as f:\n",
        "        now = dt.datetime.now()\n",
        "        t = now.strftime(\"%Y-%m-%d %H:%M\")\n",
        "        f.write(str(t) + '\\n')\n",
        "    return 'Greeted'\n",
        "def respond():\n",
        "    return 'Greet Responded Again'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: This module is deprecated. Please use `airflow.operators.bash`.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/\u001b[0m\u001b[1;33mipykernel_launcher.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m4\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: This module is deprecated. Please use `airflow.operators.bash`.\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">5</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: This module is deprecated. Please use `airflow.operators.python`.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/\u001b[0m\u001b[1;33mipykernel_launcher.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m5\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: This module is deprecated. Please use `airflow.operators.python`.\u001b[0m\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXdFGOe1A_-i"
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.operators.bash_operator import BashOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "\n",
        "def greet():\n",
        "    print('Writing in file')\n",
        "    with open('path/to/file/greet.txt', 'a+', encoding='utf8') as f:\n",
        "        now = dt.datetime.now()\n",
        "        t = now.strftime(\"%Y-%m-%d %H:%M\")\n",
        "        f.write(str(t) + '\\n')\n",
        "    return 'Greeted'\n",
        "def respond():\n",
        "    return 'Greet Responded Again'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd6EkuJPBhrw"
      },
      "source": [
        "greet\n",
        "  \n",
        "import datetime as dt\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.operators.bash_operator import BashOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "\n",
        "def greet():\n",
        "    print('Writing in file')\n",
        "    with open('greet.txt', 'a+', encoding='utf8') as f:\n",
        "        now = dt.datetime.now()\n",
        "        t = now.strftime(\"%Y-%m-%d %H:%M\")\n",
        "        f.write(str(t) + '\\n')\n",
        "    return 'Greeted'\n",
        "\n",
        "\n",
        "def respond():\n",
        "    return 'Greet Responded Again'\n",
        "\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'start_date': dt.datetime(2018, 9, 24, 10, 00, 00),\n",
        "    'concurrency': 1,\n",
        "    'retries': 0\n",
        "}\n",
        "\n",
        "with DAG('my_simple_dag',\n",
        "         catchup=False,\n",
        "         default_args=default_args,\n",
        "         schedule_interval='*/10 * * * *',\n",
        "         # schedule_interval=None,\n",
        "         ) as dag:\n",
        "    opr_hello = BashOperator(task_id='say_Hi',\n",
        "                             bash_command='echo \"Hi!!\"')\n",
        "\n",
        "    opr_greet = PythonOperator(task_id='greet',\n",
        "                               python_callable=greet)\n",
        "    opr_sleep = BashOperator(task_id='sleep_me',\n",
        "                             bash_command='sleep 5')\n",
        "\n",
        "    opr_respond = PythonOperator(task_id='respond',\n",
        "                                 python_callable=respond)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWI1WgiRCDHe",
        "outputId": "feb374e3-ebf5-4c57-b7e1-4adbbeab0bb0"
      },
      "source": [
        "opr_hello"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(BashOperator): say_Hi>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wQrh3cr7Bm2-",
        "outputId": "836d4e9b-374d-4929-f7c1-c517633c1a6d"
      },
      "source": [
        "greet()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing in file\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Greeted'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5ycBa6EopEs"
      },
      "source": [
        "def python_func():\n",
        "  #do something\n",
        "  pass\n",
        "  # if you return a value, other tasks can use it through xcom\n",
        "\n",
        "t_python_oper = PythonOperator(\n",
        "                    task_id=\"task_name\",\n",
        "                    python_callable=python_func,\n",
        "                    dag=dag)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN4oyweqpAQz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdAdD6Zgo0kJ"
      },
      "source": [
        "python_func()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "hFryZkJvpAu4",
        "outputId": "9ed216a8-8e4b-4366-885c-d35431c8e542"
      },
      "source": [
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import requests\n",
        "from airflow import DAG\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "#===================   dag config  =====================\n",
        "default_args = {\n",
        "    'owner': 'muller'\n",
        "}\n",
        "\n",
        "dag = DAG('example_python_operator',\n",
        "           catchup=False,\n",
        "           start_date = datetime(2019, 1, 1),\n",
        "           schedule_interval='@daily',\n",
        "           default_args=default_args)\n",
        "#============================== Python Operator ================================\n",
        "PATTERN = 'storeIndexInfo\\(\"S&P 500\",\"(.+?)\"'\n",
        "extractor = re.compile(PATTERN)\n",
        "\n",
        "def get_SnP500():\n",
        "    \"\"\"\n",
        "    use requests library to scrapy site nasdaq\n",
        "    to get S&P 500 value\n",
        "    \"\"\"\n",
        "    res = requests.get(\"https://www.nasdaq.com/\")\n",
        "    value = extractor.findall(res.text)[0]\n",
        "    return value\n",
        "\n",
        "t_get_SnP500 = PythonOperator(\n",
        "                    task_id=\"get_SnP500_value\",\n",
        "                    python_callable=get_SnP500,\n",
        "                    dag=dag)\n",
        "\n",
        "#===============================================================================\n",
        "t_send_email = DummyOperator(\n",
        "    task_id='send_email',\n",
        "    dag=dag,\n",
        ")\n",
        "#===============================================================================\n",
        "t_get_SnP500 >> t_send_email"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">6</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: This module is deprecated. Please use `airflow.operators.dummy`.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/\u001b[0m\u001b[1;33mipykernel_launcher.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m6\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: This module is deprecated. Please use `airflow.operators.dummy`.\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(DummyOperator): send_email>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "lzzX-fUCpyPz",
        "outputId": "45d16ca4-ed3a-4349-e04a-3f5af8f128e8"
      },
      "source": [
        "get_SnP500()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-24718c26dcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_SnP500\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-2525096d41f7>\u001b[0m in \u001b[0;36mget_SnP500\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mP\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.nasdaq.com/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XfehhJ3q17Y",
        "outputId": "e85e4ec2-4cf7-41e4-bea4-6d9a98404e6d"
      },
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.bash_operator import BashOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'muller',\n",
        "    'depends_on_past': False,\n",
        "    'start_date': datetime(2019, 8, 1),\n",
        "    'email': ['airflow@example.com'],\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(minutes=5),\n",
        "}\n",
        "\n",
        "dag = DAG('daily_report',\n",
        "          default_args=default_args,\n",
        "          schedule_interval=timedelta(days=1))\n",
        "\n",
        "# t1, t2 and t3 are examples of tasks created by instantiating operators\n",
        "t1_a = BashOperator(\n",
        "    task_id='get_db_A',\n",
        "    bash_command='sh script_A.sh',\n",
        "    dag=dag)\n",
        "\n",
        "t1_b = BashOperator(\n",
        "    task_id='get_db_B',\n",
        "    bash_command='sh script_B.sh',\n",
        "    dag=dag)\n",
        "\n",
        "t1_c = BashOperator(\n",
        "    task_id='get_db_C',\n",
        "    bash_command='sh script_C.sh',\n",
        "    dag=dag)\n",
        "\n",
        "t2 = BashOperator(\n",
        "    task_id='join_data',\n",
        "    bash_command='sh join_data.sh',\n",
        "    dag=dag)\n",
        "\n",
        "t3 = BashOperator(\n",
        "    task_id='analyze',\n",
        "    bash_command='sh analyze.sh',\n",
        "    dag=dag)\n",
        "\n",
        "\n",
        "(t1_a, t1_b, t1_c) >> t2 >> t3"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(BashOperator): analyze>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blky9FQlxo4m",
        "outputId": "59fdd174-dc66-4a05-c7ea-226f8ed11c2b"
      },
      "source": [
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import requests\n",
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import BranchPythonOperator\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.operators.email_operator import EmailOperator\n",
        "#===================   dag config  =====================\n",
        "default_args = {\n",
        "    'owner': 'muller'\n",
        "}\n",
        "\n",
        "dag = DAG('example_email_operator',\n",
        "           catchup=False,\n",
        "           start_date = datetime(2019, 1, 1),\n",
        "           schedule_interval='@daily',\n",
        "           default_args=default_args)\n",
        "#=========================  Python Branch Operator  ============================\n",
        "PATTERN = 'storeIndexInfo\\(\"S&P 500\",\"(.+?)\"'\n",
        "extractor = re.compile(PATTERN)\n",
        "\n",
        "def if_value_higher_3000():\n",
        "    \"\"\"\n",
        "    This function shows\n",
        "    1. get value from website\n",
        "    2. if value > 3000, we send email as an alert, otherwise we do nothing\n",
        "    python branch operator should return \"task name\" as a choice\n",
        "    \"\"\"\n",
        "    res = requests.get(\"https://www.nasdaq.com/\")\n",
        "    SnP500_value = extractor.findall(res.text)[0]\n",
        "    # As we are going to test email operator,\n",
        "    # we set it to Ture\n",
        "    if True:\n",
        "        return 'send_email'\n",
        "    else:\n",
        "        return 'do_nothing'\n",
        "\n",
        "t_get_SnP500 = BranchPythonOperator(\n",
        "    task_id='get_SnP500_value',\n",
        "    python_callable=if_value_higher_3000,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "t_send_email = EmailOperator(\n",
        "            task_id='send_email',\n",
        "            subject=\"Today's S&P 500 value\",\n",
        "            to=\"muller79924@gmail.com\",\n",
        "            # please replace it with your own email address\n",
        "            # otherwise, I will receive your mail...\n",
        "            html_content=\"Hey, it is higher than 3000\",\n",
        "            dag=dag)\n",
        "\n",
        "t_do_nothing = DummyOperator(\n",
        "    task_id='do_nothing',\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "t_get_SnP500 >> (t_send_email, t_do_nothing)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Task(EmailOperator): send_email>, <Task(DummyOperator): do_nothing>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "i-stDoTOzhHV",
        "outputId": "64bbabfd-dd48-4745-92ed-ae1e90ca4990"
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "from airflow.models import DAG\n",
        "from airflow.models import Variable\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "\n",
        "# Create JSON Variable if it doesn't exist\n",
        "\n",
        "CUSTOMERS = [\n",
        "    {\n",
        "        \"customer_name\": \"Faux Customer\",\n",
        "        \"customer_id\": \"faux_customer\",\n",
        "        \"email\": [\"admin@fauxcustomer.com\", \"admin@astronomer.io\"],\n",
        "        \"schedule_interval\": None,\n",
        "        \"enabled\": True,\n",
        "    },\n",
        "    {\n",
        "        \"customer_name\": \"Bogus Customer\",\n",
        "        \"customer_id\": \"bogus_customer\",\n",
        "        \"email\": [\"admin@boguscustomer.com\", \"admin@astronomer.io\"],\n",
        "        \"schedule_interval\": \"@once\",\n",
        "        \"enabled\": True,\n",
        "    },\n",
        "]\n",
        "\n",
        "# Get JSON Variable\n",
        "CUSTOMERS = Variable.get(\"customer_list\", default_var=CUSTOMERS)\n",
        "\n",
        "\n",
        "def create_dag(customer):\n",
        "    \"\"\"\n",
        "    Accepts a customer parameters dict and\n",
        "    overrides default args to create a DAG object\n",
        "    Returns: DAG() Object\n",
        "    \"\"\"\n",
        "    default_args = {\n",
        "        \"owner\": \"airflow\",\n",
        "        \"depends_on_past\": False,\n",
        "        \"email\": \"xyz@xyz.com\",\n",
        "        \"retries\": 1,\n",
        "        \"retry_delay\": timedelta(minutes=5),\n",
        "        \"start_date\": datetime(2017, 1, 1, 0, 0),\n",
        "        \"end_date\": None,\n",
        "    }\n",
        "\n",
        "    \"\"\"\n",
        "    This allows DAG parameters to be passed in from the Variable if\n",
        "    a customer needs something specific overridden in their DAG.\n",
        "    Consider how email being passed in from the customer object\n",
        "    overrides email in the resulting replaced_args object.\n",
        "    \"\"\"\n",
        "    replaced_args = {\n",
        "        k: default_args[k] if customer.get(k, None) is None else customer[k]\n",
        "        for k in default_args\n",
        "    }\n",
        "\n",
        "    dag_id = \"{base_name}_{id}\".format(\n",
        "        base_name=\"load_clickstream_data\", id=customer[\"customer_id\"]\n",
        "    )\n",
        "\n",
        "    return DAG(\n",
        "        dag_id=dag_id,\n",
        "        default_args=replaced_args,\n",
        "        schedule_interval=customer[\"schedule_interval\"],\n",
        "    )\n",
        "\n",
        "    # Loop customers array of containing customer objects\n",
        "    for cust in CUSTOMERS:\n",
        "        if cust[\"enabled\"]:\n",
        "\n",
        "            dag = create_dag(cust)\n",
        "\n",
        "            globals()[dag.dag_id] = dag\n",
        "\n",
        "            extract = DummyOperator(task_id=\"extract_data\", dag=dag)\n",
        "\n",
        "            transform = DummyOperator(task_id=\"transform_data\", dag=dag)\n",
        "\n",
        "            load = DummyOperator(task_id=\"load_data\", dag=dag)\n",
        "\n",
        "            extract >> transform >> load\n",
        "\n",
        "        else:\n",
        "            # TODO Create but programmatically pause\n",
        "            pass"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperationalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1277\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: variable",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1bd29ccab760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Get JSON Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mCUSTOMERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"customer_list\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCUSTOMERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/airflow/models/variable.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(cls, key, default_var, deserialize_json)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mdeserialize_json\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDeserialize\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mvar_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_from_secrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvar_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__NO_DEFAULT_SENTINEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/airflow/models/variable.py\u001b[0m in \u001b[0;36mget_variable_from_secrets\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \"\"\"\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msecrets_backend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mensure_secrets_loaded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mvar_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecrets_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvar_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/airflow/utils/session.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/airflow/secrets/metastore.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, key, session)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mvar_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpunge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvar_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3427\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3201\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_existing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_and_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_execute_and_instances\u001b[0;34m(self, querycontext)\u001b[0m\n\u001b[1;32m   3558\u001b[0m         )\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3560\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerycontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1009\u001b[0m             )\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         )\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1317\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m             )\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                 util.raise_(\n\u001b[0;32m-> 1511\u001b[0;31m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m                 )\n\u001b[1;32m   1513\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1277\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m                     )\n\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: variable\n[SQL: SELECT variable.val AS variable_val, variable.id AS variable_id, variable.\"key\" AS variable_key, variable.description AS variable_description, variable.is_encrypted AS variable_is_encrypted \nFROM variable \nWHERE variable.\"key\" = ?\n LIMIT ? OFFSET ?]\n[parameters: ('customer_list', 1, 0)]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TbeppZL14nX"
      },
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.bash_operator import BashOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'depends_on_past': False,\n",
        "    'start_date': datetime(2015, 6, 1),\n",
        "    'email': ['airflow@example.com'],\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(minutes=5),\n",
        "    # 'queue': 'bash_queue',\n",
        "    # 'pool': 'backfill',\n",
        "    # 'priority_weight': 10,\n",
        "    # 'end_date': datetime(2016, 1, 1),\n",
        "}\n",
        "\n",
        "dag = DAG('tutorial', default_args=default_args)\n",
        "\n",
        "# t1, t2 and t3 are examples of tasks created by instantiating operators\n",
        "t1 = BashOperator(\n",
        "    task_id='print_date',\n",
        "    bash_command='date',\n",
        "    dag=dag)\n",
        "\n",
        "t2 = BashOperator(\n",
        "    task_id='sleep',\n",
        "    bash_command='sleep 5',\n",
        "    retries=3,\n",
        "    dag=dag)\n",
        "\n",
        "templated_command = \"\"\"\n",
        "    {% for i in range(5) %}\n",
        "        echo \"{{ ds }}\"\n",
        "        echo \"{{ macros.ds_add(ds, 7)}}\"\n",
        "        echo \"{{ params.my_param }}\"\n",
        "    {% endfor %}\n",
        "\"\"\"\n",
        "\n",
        "t3 = BashOperator(\n",
        "    task_id='templated',\n",
        "    bash_command=templated_command,\n",
        "    params={'my_param': 'Parameter I passed in'},\n",
        "    dag=dag)\n",
        "\n",
        "t2.set_upstream(t1)\n",
        "t3.set_upstream(t1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX3U2lSCWPL8",
        "outputId": "2d7d0f97-35fd-461c-f1b3-ad971086b206"
      },
      "source": [
        "t1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(BashOperator): print_date>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CID2GMtfU6Tv"
      },
      "source": [
        "#import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "\n",
        "def create_engine_mysql():\n",
        "    #https://docs.sqlalchemy.org/en/13/core/engines.html\n",
        "    #dialect + driver: // username: password @ host:port / database\n",
        "\n",
        "    engine = create_engine('mysql://sa:password@ea-airflow-opsathon.c6yf9ed3gd4c.us-west-2.rds.amazonaws.com/airnick', echo=False)\n",
        "    return engine\n",
        "\n",
        "def create_engine_pgsql():\n",
        "    #engine = create_engine(DB_CONN)\n",
        "    #dialect + driver: // username: password @ host:port / database\n",
        "    engine = create_engine('postgresql+psycopg2://postgres:pg@localhost/airflow', echo=False)\n",
        "    return engine\n",
        "\n",
        "\n",
        "def insert_to_db(engine, df, table_name):\n",
        "    df.to_sql(table_name, con=engine, if_exists=\"append\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TkTBLZ1Ccofb",
        "outputId": "29fb9ff5-23b9-463a-df17-48b86515e82a"
      },
      "source": [
        "!pip install apache-airflow-providers-microsoft-azure"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-airflow-providers-microsoft-azure\n",
            "  Downloading apache_airflow_providers_microsoft_azure-3.1.1-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-datalake-store>=0.5.0\n",
            "  Downloading azure_mgmt_datalake_store-0.5.0-py2.py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting azure-batch>=8.0.0\n",
            "  Downloading azure_batch-11.0.0-py2.py3-none-any.whl (228 kB)\n",
            "\u001b[K     |████████████████████████████████| 228 kB 21.7 MB/s \n",
            "\u001b[?25hCollecting azure-keyvault>=4.1.0\n",
            "  Downloading azure_keyvault-4.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting azure-mgmt-datafactory<2.0,>=1.0.0\n",
            "  Downloading azure_mgmt_datafactory-1.1.0-py2.py3-none-any.whl (477 kB)\n",
            "\u001b[K     |████████████████████████████████| 477 kB 51.4 MB/s \n",
            "\u001b[?25hCollecting azure-storage-file>=2.1.0\n",
            "  Downloading azure_storage_file-2.1.0-py2.py3-none-any.whl (36 kB)\n",
            "Collecting azure-mgmt-resource>=2.2.0\n",
            "  Downloading azure_mgmt_resource-20.0.0-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 59.3 MB/s \n",
            "\u001b[?25hCollecting azure-storage-common>=2.1.0\n",
            "  Downloading azure_storage_common-2.1.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting azure-storage-blob>=12.7.0\n",
            "  Downloading azure_storage_blob-12.9.0-py2.py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting azure-kusto-data<0.1,>=0.0.43\n",
            "  Downloading azure_kusto_data-0.0.45-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: apache-airflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow-providers-microsoft-azure) (2.1.4)\n",
            "Collecting azure-cosmos<4,>=3.0.1\n",
            "  Downloading azure_cosmos-3.2.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 44.9 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-containerinstance<2.0,>=1.5.0\n",
            "  Downloading azure_mgmt_containerinstance-1.5.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting azure-datalake-store>=0.0.45\n",
            "  Downloading azure_datalake_store-0.0.52-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 277 kB/s \n",
            "\u001b[?25hCollecting azure-identity>=1.3.1\n",
            "  Downloading azure_identity-1.6.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (4.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1,~=1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.0.1)\n",
            "Requirement already satisfied: python-nvd3~=0.15.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.15.0)\n",
            "Requirement already satisfied: unicodecsv>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.0)\n",
            "Requirement already satisfied: apache-airflow-providers-http in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.0.1)\n",
            "Requirement already satisfied: flask-wtf<0.15,>=0.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.14.3)\n",
            "Requirement already satisfied: gunicorn>=19.5.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (20.1.0)\n",
            "Requirement already satisfied: openapi-spec-validator>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (5.4.1)\n",
            "Requirement already satisfied: cached-property~=1.5 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.5.2)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.5.1)\n",
            "Requirement already satisfied: flask-caching<2.0.0,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.10.1)\n",
            "Requirement already satisfied: rich>=9.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (10.11.0)\n",
            "Requirement already satisfied: cryptography>=0.9.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.4.8)\n",
            "Requirement already satisfied: pygments<3.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.6.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.18 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.3.24)\n",
            "Requirement already satisfied: flask-login<0.5,>=0.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.4.1)\n",
            "Requirement already satisfied: python-slugify<5.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (4.0.1)\n",
            "Requirement already satisfied: psutil<6.0.0,>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (5.4.8)\n",
            "Requirement already satisfied: apache-airflow-providers-ftp in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.0.1)\n",
            "Requirement already satisfied: jinja2<4,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.11.3)\n",
            "Requirement already satisfied: lockfile>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.12.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.0)\n",
            "Requirement already satisfied: pyjwt<2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.7.1)\n",
            "Requirement already satisfied: cattrs<1.7.0,~=1.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.5.0)\n",
            "Requirement already satisfied: attrs<21.0,>=20.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (20.3.0)\n",
            "Requirement already satisfied: tenacity~=6.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (6.2.0)\n",
            "Requirement already satisfied: clickclick>=1.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (20.10.2)\n",
            "Requirement already satisfied: markdown<4.0,>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.7.4.3)\n",
            "Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.6.0)\n",
            "Requirement already satisfied: jsonschema~=3.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.2.0)\n",
            "Requirement already satisfied: pandas<2.0,>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.5)\n",
            "Requirement already satisfied: python-daemon>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.3.0)\n",
            "Requirement already satisfied: importlib-resources~=1.4 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.5.0)\n",
            "Requirement already satisfied: sqlalchemy-jsonfield~=1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.0.0)\n",
            "Requirement already satisfied: dill<0.4,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.3.4)\n",
            "Requirement already satisfied: python3-openid~=3.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.2.0)\n",
            "Requirement already satisfied: flask-appbuilder<4.0.0,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.3.3)\n",
            "Requirement already satisfied: apache-airflow-providers-sqlite in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.0.1)\n",
            "Requirement already satisfied: graphviz>=0.12 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.17)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.19.0)\n",
            "Requirement already satisfied: setproctitle<2,>=1.1.8 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.2.2)\n",
            "Requirement already satisfied: tabulate<0.9,>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.8.9)\n",
            "Requirement already satisfied: docutils<0.17 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.16)\n",
            "Requirement already satisfied: argcomplete~=1.10 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.12.3)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.8.2)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.4)\n",
            "Requirement already satisfied: flask<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.4)\n",
            "Requirement already satisfied: swagger-ui-bundle>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.0.9)\n",
            "Requirement already satisfied: colorlog<6.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (5.0.1)\n",
            "Requirement already satisfied: marshmallow-oneofschema>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.0.1)\n",
            "Requirement already satisfied: pendulum~=2.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.1.2)\n",
            "Requirement already satisfied: apache-airflow-providers-imap in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.0.1)\n",
            "Requirement already satisfied: markupsafe<2.0,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.1)\n",
            "Requirement already satisfied: iso8601>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.1.16)\n",
            "Requirement already satisfied: alembic<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.7.3)\n",
            "Requirement already satisfied: croniter<1.1,>=0.3.17 in /usr/local/lib/python3.7/dist-packages (from apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.0.15)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic<2.0,>=1.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.5)\n",
            "Collecting msrest>=0.6.21\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting msrestazure<2.0.0,>=0.4.32\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.6 in /usr/local/lib/python3.7/dist-packages (from azure-cosmos<4,>=3.0.1->apache-airflow-providers-microsoft-azure) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from azure-cosmos<4,>=3.0.1->apache-airflow-providers-microsoft-azure) (2.26.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from azure-datalake-store>=0.0.45->apache-airflow-providers-microsoft-azure) (1.14.6)\n",
            "Collecting adal>=0.4.2\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting msal-extensions~=0.3.0\n",
            "  Downloading msal_extensions-0.3.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting msal<2.0.0,>=1.7.0\n",
            "  Downloading msal-1.14.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.0.0\n",
            "  Downloading azure_core-1.18.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting azure-keyvault-keys~=4.1\n",
            "  Downloading azure_keyvault_keys-4.4.0-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[K     |████████████████████████████████| 289 kB 70.5 MB/s \n",
            "\u001b[?25hCollecting azure-keyvault-certificates~=4.1\n",
            "  Downloading azure_keyvault_certificates-4.3.0-py2.py3-none-any.whl (276 kB)\n",
            "\u001b[K     |████████████████████████████████| 276 kB 20.5 MB/s \n",
            "\u001b[?25hCollecting azure-keyvault-secrets~=4.1\n",
            "  Downloading azure_keyvault_secrets-4.3.0-py2.py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 32.8 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting azure-mgmt-datalake-nspkg>=2.0.0\n",
            "  Downloading azure_mgmt_datalake_nspkg-3.0.1-py3-none-any.whl (1.7 kB)\n",
            "Collecting azure-mgmt-nspkg>=3.0.0\n",
            "  Downloading azure_mgmt_nspkg-3.0.2-py3-none-any.whl (1.6 kB)\n",
            "Collecting azure-nspkg>=3.0.0\n",
            "  Downloading azure_nspkg-3.0.2-py3-none-any.whl (1.5 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from clickclick>=1.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (7.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->azure-datalake-store>=0.0.45->apache-airflow-providers-microsoft-azure) (2.20)\n",
            "Requirement already satisfied: Flask-JWT-Extended<4,>=3.18 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.25.1)\n",
            "Requirement already satisfied: sqlalchemy-utils<1,>=0.32.21 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.37.8)\n",
            "Requirement already satisfied: marshmallow<4,>=3 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.13.0)\n",
            "Requirement already satisfied: Flask-Babel<2,>=1 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.0.0)\n",
            "Requirement already satisfied: marshmallow-sqlalchemy<0.24.0,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.23.1)\n",
            "Requirement already satisfied: Flask-OpenID<2,>=1.2.5 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.3.0)\n",
            "Requirement already satisfied: prison<1.0.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.2.1)\n",
            "Requirement already satisfied: marshmallow-enum<2,>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.5.1)\n",
            "Requirement already satisfied: colorama<1,>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.4.4)\n",
            "Requirement already satisfied: apispec[yaml]<4,>=3.3 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.3.2)\n",
            "Requirement already satisfied: email-validator<2,>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.1.3)\n",
            "Requirement already satisfied: Flask-SQLAlchemy<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.5.1)\n",
            "Requirement already satisfied: dnspython>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from email-validator<2,>=1.0.5->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.1.0)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from email-validator<2,>=1.0.5->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.10)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel<2,>=1->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.9.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel<2,>=1->flask-appbuilder<4.0.0,>=3.3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2018.9)\n",
            "Requirement already satisfied: WTForms in /usr/local/lib/python3.7/dist-packages (from flask-wtf<0.15,>=0.14.3->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2.3.3)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn>=19.5.0->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.5.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema~=3.0->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.18.0)\n",
            "Collecting portalocker~=1.0\n",
            "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-batch>=8.0.0->apache-airflow-providers-microsoft-azure) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-batch>=8.0.0->apache-airflow-providers-microsoft-azure) (2021.5.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-batch>=8.0.0->apache-airflow-providers-microsoft-azure) (1.3.0)\n",
            "Requirement already satisfied: openapi-schema-validator in /usr/local/lib/python3.7/dist-packages (from openapi-spec-validator>=0.2.4->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.1.5)\n",
            "Requirement already satisfied: pytzdata>=2020.1 in /usr/local/lib/python3.7/dist-packages (from pendulum~=2.0->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (2020.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify<5.0,>=3.0.0->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from python3-openid~=3.2->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->azure-cosmos<4,>=3.0.1->apache-airflow-providers-microsoft-azure) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->azure-cosmos<4,>=3.0.1->apache-airflow-providers-microsoft-azure) (2.0.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-batch>=8.0.0->apache-airflow-providers-microsoft-azure) (3.1.1)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=9.2.0->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.9.1)\n",
            "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from httpx->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.13.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.2.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (1.5.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (3.3.2)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx->apache-airflow>=2.1.0->apache-airflow-providers-microsoft-azure) (0.12.0)\n",
            "Installing collected packages: azure-nspkg, portalocker, msrest, msal, azure-mgmt-nspkg, azure-core, azure-common, adal, msrestazure, msal-extensions, azure-storage-common, azure-mgmt-datalake-nspkg, azure-mgmt-core, azure-keyvault-secrets, azure-keyvault-keys, azure-keyvault-certificates, azure-storage-file, azure-storage-blob, azure-mgmt-resource, azure-mgmt-datalake-store, azure-mgmt-datafactory, azure-mgmt-containerinstance, azure-kusto-data, azure-keyvault, azure-identity, azure-datalake-store, azure-cosmos, azure-batch, apache-airflow-providers-microsoft-azure\n",
            "Successfully installed adal-1.2.7 apache-airflow-providers-microsoft-azure-3.1.1 azure-batch-11.0.0 azure-common-1.1.27 azure-core-1.18.0 azure-cosmos-3.2.0 azure-datalake-store-0.0.52 azure-identity-1.6.1 azure-keyvault-4.1.0 azure-keyvault-certificates-4.3.0 azure-keyvault-keys-4.4.0 azure-keyvault-secrets-4.3.0 azure-kusto-data-0.0.45 azure-mgmt-containerinstance-1.5.0 azure-mgmt-core-1.3.0 azure-mgmt-datafactory-1.1.0 azure-mgmt-datalake-nspkg-3.0.1 azure-mgmt-datalake-store-0.5.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-20.0.0 azure-nspkg-3.0.2 azure-storage-blob-12.9.0 azure-storage-common-2.1.0 azure-storage-file-2.1.0 msal-1.14.0 msal-extensions-0.3.0 msrest-0.6.21 msrestazure-0.6.4 portalocker-1.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "airflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTt08PxOcS5Y",
        "outputId": "157d8eec-68fd-454b-d83d-d2167071b9be"
      },
      "source": [
        "from airflow import DAG\n",
        "from datetime import datetime, timedelta\n",
        "from airflow.operators.email_operator import EmailOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from airflow.providers.microsoft.azure.hooks.azure_data_factory import AzureDataFactoryHook\n",
        "from airflow.providers.microsoft.azure.hooks.wasb import WasbHook\n",
        "\n",
        "\n",
        "#Get yesterday's date, in the correct format\n",
        "yesterday_date = '{{ yesterday_ds_nodash }}'\n",
        "\n",
        "#Define Great Expectations file paths\n",
        "data_dir = '/usr/local/airflow/include/data/'\n",
        "data_file_path = '/usr/local/airflow/include/data/'\n",
        "ge_root_dir = '/usr/local/airflow/include/great_expectations'\n",
        "\n",
        "def run_adf_pipeline(pipeline_name, date):\n",
        "    '''Runs an Azure Data Factory pipeline using the AzureDataFactoryHook and passes in a date parameter\n",
        "    '''\n",
        "    \n",
        "    #Create a dictionary with date parameter \n",
        "    params = {}\n",
        "    params[\"date\"] = date\n",
        "\n",
        "    #Make connection to ADF, and run pipeline with parameter\n",
        "    hook = AzureDataFactoryHook('azure_data_factory_conn')\n",
        "    hook.run_pipeline(pipeline_name, parameters=params)\n",
        "\n",
        "def get_azure_blob_files(blobname, output_filename):\n",
        "    '''Downloads file from Azure blob storage\n",
        "    '''\n",
        "    azure = WasbHook(wasb_conn_id='azure_blob')\n",
        "    azure.get_file(output_filename, container_name='covid-data', blob_name=blobname)\n",
        "    \n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'depends_on_past': False,\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 0,\n",
        "    'retry_delay': timedelta(minutes=5)\n",
        "}\n",
        "\n",
        "with DAG('adf_great_expectations',\n",
        "         start_date=datetime(2021, 1, 1),\n",
        "         max_active_runs=1,\n",
        "         schedule_interval='@daily', \n",
        "         default_args=default_args,\n",
        "         catchup=False\n",
        "         ) as dag:\n",
        "\n",
        "         run_pipeline = PythonOperator(\n",
        "            task_id='run_pipeline',\n",
        "            python_callable=run_adf_pipeline,\n",
        "            op_kwargs={'pipeline_name': 'pipeline1', 'date': yesterday_date}\n",
        "         )\n",
        "\n",
        "         download_data = PythonOperator(\n",
        "            task_id='download_data',\n",
        "            python_callable=get_azure_blob_files,\n",
        "            op_kwargs={'blobname': 'or/'+ yesterday_date +'.csv', 'output_filename': data_file_path+'or_'+yesterday_date+'.csv'}\n",
        "         )\n",
        "\n",
        "         \n",
        "         send_email = EmailOperator(\n",
        "            task_id='send_email',\n",
        "            to='noreply@astronomer.io',\n",
        "            subject='Covid to S3 DAG',\n",
        "            html_content='<p>The great expectations checks passed successfully. <p>'\n",
        "        )\n",
        "\n",
        "run_pipeline >> download_data >> send_email\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(EmailOperator): send_email>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeSTvOlHdyJc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "wm01d3KSbgob",
        "outputId": "7fb73bd3-c137-4ff8-c126-c97c5c7fea3b"
      },
      "source": [
        "import unittest\n",
        "\n",
        "\n",
        "class TestSum(unittest.TestCase):\n",
        "\n",
        "    def test_sum(self):\n",
        "        self.assertEqual(sum([1, 2, 3]), 6, \"Should be 6\")\n",
        "\n",
        "    def test_sum_tuple(self):\n",
        "        self.assertEqual(sum((2, 2, 2)), 6, \"Should be 6\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "E\n",
            "======================================================================\n",
            "ERROR: /root/ (unittest.loader._FailedTest)\n",
            "----------------------------------------------------------------------\n",
            "AttributeError: module '__main__' has no attribute '/root/'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.003s\n",
            "\n",
            "FAILED (errors=1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2890</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: To exit: use </span><span style=\"color: #808000; text-decoration-color: #808000\">'exit'</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">'quit'</span><span style=\"color: #808000; text-decoration-color: #808000\">, or Ctrl-D.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m2890\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: To exit: use \u001b[0m\u001b[33m'exit'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'quit'\u001b[0m\u001b[33m, or Ctrl-D.\u001b[0m\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yteesrq4XK9q",
        "outputId": "da15349c-65fc-458c-8dcc-16c10c30f606"
      },
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import requests\n",
        "\n",
        "def api_function(**kwargs):\n",
        "    url = 'https://covidtracking.com/api/v1/states/'\n",
        "    filename = '{0}/{1}.csv'.format('wa', '2020-03-31')\n",
        "    res = requests.get(url+filename)\n",
        "\n",
        "with DAG('pool_unimportant_dag',\n",
        "         start_date=datetime(2021, 8, 1),\n",
        "         schedule_interval=timedelta(minutes=30),\n",
        "         catchup=False,\n",
        "         default_args={\n",
        "             'retries': 1,\n",
        "             'retry_delay': timedelta(minutes=5)\n",
        "         }\n",
        "         ) as dag:\n",
        "\n",
        "    task_w = DummyOperator(\n",
        "        task_id='start'\n",
        "    )\n",
        "\n",
        "    task_x = PythonOperator(\n",
        "        task_id='task_x',\n",
        "        python_callable=api_function,\n",
        "        pool='api_pool',\n",
        "        priority_weight=2\n",
        "    )\n",
        "\n",
        "    task_y = PythonOperator(\n",
        "        task_id='task_y',\n",
        "        python_callable=api_function,\n",
        "        pool='api_pool'\n",
        "    )\n",
        "\n",
        "    task_z = DummyOperator(\n",
        "        task_id='end'\n",
        "    )\n",
        "\n",
        "task_w >> [task_x, task_y] >> task_z\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(DummyOperator): end>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy_nOjD7er_7",
        "outputId": "fbe1ce13-4b79-417c-a2e5-aa05e034412b"
      },
      "source": [
        "#sla\n",
        "from airflow import DAG\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def my_custom_function(ts,**kwargs):\n",
        "    print(\"task is sleeping\")\n",
        "    time.sleep(40)\n",
        "\n",
        "# Default settings applied to all tasks\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'depends_on_past': False,\n",
        "    'email_on_failure': True,\n",
        "    'email': 'noreply@astronomer.io',\n",
        "    'email_on_retry': False,\n",
        "    'sla': timedelta(seconds=30)\n",
        "}\n",
        "\n",
        "# Using a DAG context manager, you don't have to specify the dag property of each task\n",
        "with DAG('sla-dag',\n",
        "         start_date=datetime(2021, 1, 1),\n",
        "         max_active_runs=1,\n",
        "         schedule_interval=timedelta(minutes=2),\n",
        "         default_args=default_args,\n",
        "         catchup=False \n",
        "         ) as dag:\n",
        "\n",
        "    t0 = DummyOperator(\n",
        "        task_id='start'\n",
        "    )\n",
        "\n",
        "    t1 = DummyOperator(\n",
        "        task_id='end'\n",
        "    )\n",
        "\n",
        "    sla_task = PythonOperator(\n",
        "        task_id='sla_task',\n",
        "        python_callable=my_custom_function\n",
        "    )\n",
        "\n",
        "t0 >> sla_task >> t1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(DummyOperator): end>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhnBj5N9fdvG",
        "outputId": "a3d4ea44-f3d3-4564-b9c2-3e09b432655d"
      },
      "source": [
        "\n",
        "import random\n",
        "from airflow import DAG\n",
        "from airflow.operators.dummy import DummyOperator\n",
        "from airflow.operators.python import BranchPythonOperator\n",
        "from datetime import datetime\n",
        "from airflow.utils.trigger_rule import TriggerRule\n",
        "\n",
        "def return_branch(**kwargs):\n",
        "    branches = ['branch_0', 'branch_1', 'branch_2']\n",
        "    return random.choice(branches)\n",
        "\n",
        "with DAG(dag_id='branch',\n",
        "         start_date=datetime(2021, 1, 1),\n",
        "         max_active_runs=1,\n",
        "         schedule_interval=None,\n",
        "         catchup=False\n",
        "         ) as dag:\n",
        "\n",
        "    #DummyOperators\n",
        "    start = DummyOperator(task_id='start')\n",
        "    end = DummyOperator(\n",
        "        task_id='end',\n",
        "        trigger_rule=TriggerRule.ONE_SUCCESS\n",
        "    )\n",
        "\n",
        "    branching = BranchPythonOperator(\n",
        "        task_id='branching',\n",
        "        python_callable=return_branch,\n",
        "        provide_context=True\n",
        "    )\n",
        "\n",
        "start >> branching\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(BranchPythonOperator): branching>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEXFCPBNiRg1",
        "outputId": "7268c21d-3ec8-40fd-954e-30a68c86bd81"
      },
      "source": [
        "from airflow.decorators import dag, task\n",
        "from datetime import datetime\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url = 'https://covidtracking.com/api/v1/states/'\n",
        "state = 'wa'\n",
        "\n",
        "default_args = {\n",
        "    'start_date': datetime(2021, 1, 1)\n",
        "}\n",
        "\n",
        "@dag('xcom_taskflow_dag', schedule_interval='@daily', default_args=default_args, catchup=False)\n",
        "def taskflow():\n",
        "\n",
        "    @task\n",
        "    def get_testing_increase(state):\n",
        "        \"\"\"\n",
        "        Gets totalTestResultsIncrease field from Covid API for given state and returns value\n",
        "        \"\"\"\n",
        "        res = requests.get(url+'{0}/current.json'.format(state))\n",
        "        return{'testing_increase': json.loads(res.text)['totalTestResultsIncrease']}\n",
        "\n",
        "    @task\n",
        "    def analyze_testing_increases(testing_increase: int):\n",
        "        \"\"\"\n",
        "        Evaluates testing increase results\n",
        "        \"\"\"\n",
        "        print('Testing increases for {0}:'.format(state), testing_increase)\n",
        "        #run some analysis here\n",
        "\n",
        "    # Invoke functions to create tasks and define dependencies\n",
        "    analyze_testing_increases(get_testing_increase(state))\n",
        "\n",
        "taskflow()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DAG: xcom_taskflow_dag>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_t03sKBimgQ",
        "outputId": "ebd00acf-b6f2-48e9-dc3a-33ae29ef44b3"
      },
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url = 'https://covidtracking.com/api/v1/states/'\n",
        "state = 'wa'\n",
        "\n",
        "def get_testing_increase(state, ti):\n",
        "    \"\"\"\n",
        "    Gets totalTestResultsIncrease field from Covid API for given state and returns value\n",
        "    \"\"\"\n",
        "    res = requests.get(url+'{0}/current.json'.format(state))\n",
        "    testing_increase = json.loads(res.text)['totalTestResultsIncrease']\n",
        "\n",
        "    ti.xcom_push(key='testing_increase', value=testing_increase)\n",
        "\n",
        "def analyze_testing_increases(state, ti):\n",
        "    \"\"\"\n",
        "    Evaluates testing increase results\n",
        "    \"\"\"\n",
        "    testing_increases=ti.xcom_pull(key='testing_increase', task_ids='get_testing_increase_data_{0}'.format(state))\n",
        "    print('Testing increases for {0}:'.format(state), testing_increases)\n",
        "    #run some analysis here\n",
        "\n",
        "# Default settings applied to all tasks\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'depends_on_past': False,\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(minutes=5)\n",
        "}\n",
        "\n",
        "with DAG('xcom_dag',\n",
        "         start_date=datetime(2021, 1, 1),\n",
        "         max_active_runs=2,\n",
        "         schedule_interval=timedelta(minutes=30),\n",
        "         default_args=default_args,\n",
        "         catchup=False\n",
        "         ) as dag:\n",
        "\n",
        "    opr_get_covid_data = PythonOperator(\n",
        "        task_id = 'get_testing_increase_data_{0}'.format(state),\n",
        "        python_callable=get_testing_increase,\n",
        "        op_kwargs={'state':state}\n",
        "    )\n",
        "\n",
        "    opr_analyze_testing_data = PythonOperator(\n",
        "        task_id = 'analyze_data',\n",
        "        python_callable=analyze_testing_increases,\n",
        "\t\t\t\top_kwargs={'state':state}\n",
        "    )\n",
        "\n",
        "opr_get_covid_data >> opr_analyze_testing_data\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(PythonOperator): analyze_data>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}